{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswinaus/LLM_Inference/blob/main/RAG_with_Evaluation_and_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvsKbF7BJ3pw"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_community langchain_openai chromadb pymupdf nest_asyncio --quiet\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "from langchain_core.runnables import (\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough\n",
        ")\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the nest_asyncio library. This library provides a way to run asyncio code within an existing event loop, avoiding conflicts.\n",
        "\n",
        "nest_asyncio.apply(): The core it \"patches\" the asyncio event loop to allow it to run inside the existing event loop of your environment. In simpler terms, it makes sure your asynchronous code plays nicely within the notebook environment without causing errors.\n",
        "\n",
        "import os:  Line imports the os library, which is a standard Python library for interacting with the operating system."
      ],
      "metadata": {
        "id": "UjI9RblpbsmG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iPfx1M_OJ6y3"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import os\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ksz53v-J9M8",
        "outputId": "cc8b808f-0088-44ef-cea1-84aef6eb67ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5LBLYjXzKBFI"
      },
      "outputs": [],
      "source": [
        "import pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qAwTNAkKKbOn"
      },
      "outputs": [],
      "source": [
        "# Download Data\n",
        "data_dir = '/content/drive/MyDrive' # Input a data dir path from your mounted Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Br6XhDCJKgQc"
      },
      "outputs": [],
      "source": [
        "doc = pymupdf.open(f\"{data_dir}/RAG/data/TP/Intel_Financial_Statements_Year_Ended_2017.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "G4InqskVKjfK"
      },
      "outputs": [],
      "source": [
        "#Printing the content to validate\n",
        "for page in doc:\n",
        "    text = page.get_text()\n",
        "    #print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kMLNbDNBK4kz"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fQDpOg7XLWGW"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "pages=[]\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "loader = PyMuPDFLoader(f\"{data_dir}/RAG/data/TP/Intel_Financial_Statements_Year_Ended_2017.pdf\")\n",
        "# load_and_split uses RecursiveCharacterTextSplitter by default\n",
        "pages_to_persist = loader.load_and_split(text_splitter)\n",
        "pages.extend(pages_to_persist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ROttjL9nkGaD"
      },
      "outputs": [],
      "source": [
        "# split the pages into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9VVQbIZ5NT0k"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeiQrf3xNY9z",
        "outputId": "52a7ef57-ef41-4c86-89e8-c13b628b092e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-1c17cc78d791>:7: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ],
      "source": [
        "# create vector store with Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata # import filter_complex_metadata\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=pages, embedding=OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"]),persist_directory=f\"{data_dir}/RAG/VectorDB/chroma_db_RAG\")\n",
        "vectordb.persist()\n",
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "asakQ43Vs4em"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RunnablePassthrough.assign():** This function is a core part of LangChain, a framework for building language model applications. RunnablePassthrough is like a pipe that allows data to flow through while potentially modifying or adding to it. .assign() is used here to add a new key-value pair to the data being passed through.\n",
        "\n",
        "**context= :** This part specifies that the key we are adding is called context. The value associated with this key is determined by the expression on the right side of the equals sign. This context will hold the relevant information retrieved from the document.\n",
        "\n",
        "**lambda x: :** This is an anonymous function (also called a lambda function) in Python. It takes one input (x, which will be a dictionary containing the user's question) and performs an operation to produce an output. This output becomes the value of the context key.\n",
        "\n",
        "**vectordb.similarity_search(x[\"question\"], k=10):** This is where the magic happens.\n",
        "\n",
        "**vectordb** is a Chroma vector database containing the embeddings of the document you loaded earlier (Intel Financial Statements).\n",
        "similarity_search is a method that searches the vector database for the documents most similar to a given query.\n",
        "\n",
        "**x[\"question\"]** provides the user's question as the query.\n",
        "\n",
        "**k=10** specifies that we want to retrieve the top 10 most similar documents."
      ],
      "metadata": {
        "id": "ah-ri7gBckKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SgTuW3rXgvND"
      },
      "outputs": [],
      "source": [
        "#Creating a RAG Pipeline\n",
        "from operator import itemgetter\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "# RAG\n",
        "template = \"\"\"You are an AI language model Accounting assistant.Answer the following question based on this context:\n",
        "{context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "llm = ChatOpenAI(temperature=0, openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "final_rag_chain = (\n",
        "    #{\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "\n",
        "    RunnablePassthrough.assign(\n",
        "        context=lambda x: format_docs(vectordb.similarity_search(x[\"question\"], k=10)),\n",
        "    )\n",
        "\n",
        "    #| RunnablePassthrough.assign(debug_context=lambda x: print(f\"Context before prompt: {x['context']}\"))\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FMYzkbeQz1-o"
      },
      "outputs": [],
      "source": [
        "question=\"Can you let me know the Identified intangible assets subject to amortization and show the difference between 2016 and 2017?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "raZD7rnKtWMl",
        "outputId": "dbdd855f-d457-46b6-cf17-da527f052a02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Identified intangible assets subject to amortization for 2016 were $8,686 million, and for 2017 were $10,577 million. The difference between 2016 and 2017 is $1,891 million.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "final_rag_chain.invoke({\"question\":question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTDUaovL6co4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0AeeBYD2Sof_"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"Can you get the total amount of Goodwill and Identified Intangible Assets?\",\n",
        "    \"How much did Intangibles such as Goodwill and other identified intangible assets did Intel gain by acquiring Altera in millions?\",\n",
        "    \"Can you list all the Intel Goodwill activities for year 2017 along with figures in millions?\",\n",
        "    \"Can let me know how much was spent on Data Center Group along for 2016 and 2017 and show the difference between 2016 and 2017?\",\n",
        "    \"Can you let me know the Identified intangible assets subject to amortization and show the difference between 2016 and 2017?\",\n",
        "    ]\n",
        "ground_truth = [\n",
        "    \"The total amount of Goodwill is $10,278 million, and the total amount of Identified Intangible Assets is $7,566 million.\",\n",
        "    \"Intel gained $13,014 million in intangibles such as Goodwill and other identified intangible assets by acquiring Altera.\",\n",
        "    \"Sure, here are the Intel Goodwill activities for the year 2017 along with figures in millions:- Client Computing Group: $4,356;- Data Center Group: $5,421;- Internet of Things Group: $1,126;- Programmable Solutions Group: $2,490;- All other: $10,996;Total: $24,389 million\",\n",
        "    \"In 2016, the amount spent on the Data Center Group was $7,520 million, and in 2017, it was $8,395 million. The difference between the two years is $875 million, with an increase in spending on the Data Center Group from 2016 to 2017.\",\n",
        "    \"The Identified intangible assets subject to amortization for 2016 were $8,686 million, and for 2017, they were $10,577 million. The difference between 2016 and 2017 is $1,891 million.\",\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAkUWnEAKb4-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heprVnxfxikf"
      },
      "outputs": [],
      "source": [
        "!pip install datasets --quiet\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "SJnwuQ3qHVb7",
        "outputId": "9fc9661b-8cf0-46b4-a2bf-122cee5d3716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-6d530bf47f64>:7: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  contexts.append([docs.page_content for docs in retriever.get_relevant_documents(question)])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  Can you get the total amount of Goodwill and I...   \n",
              "1  How much did Intangibles such as Goodwill and ...   \n",
              "2  Can you list all the Intel Goodwill activities...   \n",
              "3  Can let me know how much was spent on Data Cen...   \n",
              "4  Can you let me know the Identified intangible ...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The total amount of Goodwill is $10,278 millio...   \n",
              "1  Intel gained a total of $13,014 million in int...   \n",
              "2  - Data Center Group: $2,404 million\\n- Interne...   \n",
              "3  In 2016, the amount spent on the Data Center G...   \n",
              "4  Identified intangible assets subject to amorti...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [recognized as follows:\\n(In Millions)\\nShort-...   \n",
              "1  [The fair values of the assets acquired and li...   \n",
              "2  [—\\n$\\n4,356\\nData Center Group\\n2,404\\n2,831\\...   \n",
              "3  [Disaggregated net revenue for each period was...   \n",
              "4  [(3,634) $\\n12,745\\nDecember 31, 2016\\n(In Mil...   \n",
              "\n",
              "                                        ground_truth  \n",
              "0  The total amount of Goodwill is $10,278 millio...  \n",
              "1  Intel gained $13,014 million in intangibles su...  \n",
              "2  Sure, here are the Intel Goodwill activities f...  \n",
              "3  In 2016, the amount spent on the Data Center G...  \n",
              "4  The Identified intangible assets subject to am...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abe02410-0e6b-468e-9eba-b4b0260fa69e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can you get the total amount of Goodwill and I...</td>\n",
              "      <td>The total amount of Goodwill is $10,278 millio...</td>\n",
              "      <td>[recognized as follows:\\n(In Millions)\\nShort-...</td>\n",
              "      <td>The total amount of Goodwill is $10,278 millio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How much did Intangibles such as Goodwill and ...</td>\n",
              "      <td>Intel gained a total of $13,014 million in int...</td>\n",
              "      <td>[The fair values of the assets acquired and li...</td>\n",
              "      <td>Intel gained $13,014 million in intangibles su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can you list all the Intel Goodwill activities...</td>\n",
              "      <td>- Data Center Group: $2,404 million\\n- Interne...</td>\n",
              "      <td>[—\\n$\\n4,356\\nData Center Group\\n2,404\\n2,831\\...</td>\n",
              "      <td>Sure, here are the Intel Goodwill activities f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can let me know how much was spent on Data Cen...</td>\n",
              "      <td>In 2016, the amount spent on the Data Center G...</td>\n",
              "      <td>[Disaggregated net revenue for each period was...</td>\n",
              "      <td>In 2016, the amount spent on the Data Center G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can you let me know the Identified intangible ...</td>\n",
              "      <td>Identified intangible assets subject to amorti...</td>\n",
              "      <td>[(3,634) $\\n12,745\\nDecember 31, 2016\\n(In Mil...</td>\n",
              "      <td>The Identified intangible assets subject to am...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abe02410-0e6b-468e-9eba-b4b0260fa69e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abe02410-0e6b-468e-9eba-b4b0260fa69e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abe02410-0e6b-468e-9eba-b4b0260fa69e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-253cfaec-6a47-44ee-b43d-3f2d878841f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-253cfaec-6a47-44ee-b43d-3f2d878841f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-253cfaec-6a47-44ee-b43d-3f2d878841f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"How much did Intangibles such as Goodwill and other identified intangible assets did Intel gain by acquiring Altera in millions?\",\n          \"Can you let me know the Identified intangible assets subject to amortization and show the difference between 2016 and 2017?\",\n          \"Can you list all the Intel Goodwill activities for year 2017 along with figures in millions?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Intel gained a total of $13,014 million in intangibles, including $5,448 million in Goodwill and $7,566 million in identified intangible assets, by acquiring Altera.\",\n          \"Identified intangible assets subject to amortization for 2016 were $8,686 million, and for 2017 were $10,577 million. The difference between 2016 and 2017 is $1,891 million.\",\n          \"- Data Center Group: $2,404 million\\n- Internet of Things Group: $428 million\\n- Intel Security Group: $3,599 million\\n- Software and Services Group: $441 million\\n- Programmable Solutions Group: $0 million\\n- All other: $382 million\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Intel gained $13,014 million in intangibles such as Goodwill and other identified intangible assets by acquiring Altera.\",\n          \"The Identified intangible assets subject to amortization for 2016 were $8,686 million, and for 2017, they were $10,577 million. The difference between 2016 and 2017 is $1,891 million.\",\n          \"Sure, here are the Intel Goodwill activities for the year 2017 along with figures in millions:- Client Computing Group: $4,356;- Data Center Group: $5,421;- Internet of Things Group: $1,126;- Programmable Solutions Group: $2,490;- All other: $10,996;Total: $24,389 million\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "answers  = []\n",
        "contexts = []\n",
        "\n",
        "# traversing each question and passing into the chain to get answer from the system\n",
        "for question in questions:\n",
        "    answers.append(final_rag_chain.invoke({\"question\":question}))\n",
        "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(question)])\n",
        "\n",
        "# Preparing the dataset\n",
        "data = {\n",
        "    \"question\": questions,\n",
        "    \"answer\": answers,\n",
        "    \"contexts\": contexts,\n",
        "    \"ground_truth\": ground_truth\n",
        "}\n",
        "\n",
        "# Convert dict to dataset\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bInjb2pxtwBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23a6ad2-d3a2-402c-fa2b-f87582812a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ragas --quiet\n",
        "import ragas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYneyjx9zVDo"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/aswinaus/rag_dataset_ragas.git\n",
        "#%cd rag_dataset_ragas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmyL7E3p7acZ"
      },
      "outputs": [],
      "source": [
        "#from datasets import load_dataset\n",
        "#dataset = load_dataset('json', data_files='RAGDataset.json')\n",
        "#dataset = dataset['train']\n",
        "#print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code is focused on evaluating the performance of a Retrieval Augmented Generation (RAG) system using the ragas library. RAG systems combine information retrieval (finding relevant documents) with text generation (creating answers).\n",
        "\n",
        "**from ragas import evaluate:** This line imports the evaluate function from the ragas library. This function is the main tool for assessing the RAG system's quality.\n",
        "\n",
        "**from ragas.metrics import (...):** Here, specific evaluation metrics are imported from ragas.metrics. These metrics will be used to judge different aspects of the system's performance.\n",
        "\n",
        "**faithfulness:** Measures how well the generated answer aligns with the information provided in the retrieved documents. It checks if the answer is supported by the evidence.\n",
        "\n",
        "**answer_relevancy:** Assesses the relevance of the generated answer to the user's question. It determines if the answer addresses the question appropriately.\n",
        "\n",
        "**context_recall:** Evaluates how well the system retrieves all the necessary documents relevant to the question. A higher recall means more relevant documents are found.\n",
        "\n",
        "**context_precision:** Measures the accuracy of the retrieved documents. A higher precision means that a larger proportion of the retrieved documents are actually relevant."
      ],
      "metadata": {
        "id": "GxriZI3idob4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726,
          "referenced_widgets": [
            "4f5ec9b7886b40bfa5c08f2c6fc27f72",
            "19ab3a5cfbef4541889a5703b25d848a",
            "84ceda66e52046788c1697e4bff932ec",
            "3c458ce5565b4f5ca1271beb9c9dcfa0",
            "328088bf6bf5414c870455e9ce7d9dcb",
            "65a5ceffb89b49fdaaf298b92abc667e",
            "f1820773b6794df9917e7f8230eb509d",
            "e5e625f0268d4874a86f4fee384dc4e3",
            "84b5727cc569492da6b78ab163a2dc6a",
            "4dccdfedb7bc47d3b86e1c9b455f8bcb",
            "ee2d071a66cb41f8978d1a203d3d93ff"
          ]
        },
        "id": "mBtwVZQOHctE",
        "outputId": "e0c92a5a-be7f-4567-b199-9980486f4d1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f5ec9b7886b40bfa5c08f2c6fc27f72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          user_input  \\\n",
              "0  Can you get the total amount of Goodwill and I...   \n",
              "1  How much did Intangibles such as Goodwill and ...   \n",
              "2  Can you list all the Intel Goodwill activities...   \n",
              "3  Can let me know how much was spent on Data Cen...   \n",
              "4  Can you let me know the Identified intangible ...   \n",
              "\n",
              "                                  retrieved_contexts  \\\n",
              "0  [recognized as follows:\\n(In Millions)\\nShort-...   \n",
              "1  [The fair values of the assets acquired and li...   \n",
              "2  [—\\n$\\n4,356\\nData Center Group\\n2,404\\n2,831\\...   \n",
              "3  [Disaggregated net revenue for each period was...   \n",
              "4  [(3,634) $\\n12,745\\nDecember 31, 2016\\n(In Mil...   \n",
              "\n",
              "                                            response  \\\n",
              "0  The total amount of Goodwill is $10,278 millio...   \n",
              "1  Intel gained a total of $13,014 million in int...   \n",
              "2  - Data Center Group: $2,404 million\\n- Interne...   \n",
              "3  In 2016, the amount spent on the Data Center G...   \n",
              "4  Identified intangible assets subject to amorti...   \n",
              "\n",
              "                                           reference  context_precision  \\\n",
              "0  The total amount of Goodwill is $10,278 millio...                1.0   \n",
              "1  Intel gained $13,014 million in intangibles su...                1.0   \n",
              "2  Sure, here are the Intel Goodwill activities f...                0.0   \n",
              "3  In 2016, the amount spent on the Data Center G...                1.0   \n",
              "4  The Identified intangible assets subject to am...                1.0   \n",
              "\n",
              "   context_recall  faithfulness  answer_relevancy  \n",
              "0        0.500000      0.500000          0.972272  \n",
              "1        0.000000      0.000000          0.945473  \n",
              "2        0.166667      0.000000          0.875948  \n",
              "3        0.000000      0.000000          0.946152  \n",
              "4        0.333333      0.333333          0.960631  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-491d9ef2-942d-4f7d-9f08-ba54f32266f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can you get the total amount of Goodwill and I...</td>\n",
              "      <td>[recognized as follows:\\n(In Millions)\\nShort-...</td>\n",
              "      <td>The total amount of Goodwill is $10,278 millio...</td>\n",
              "      <td>The total amount of Goodwill is $10,278 millio...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.972272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How much did Intangibles such as Goodwill and ...</td>\n",
              "      <td>[The fair values of the assets acquired and li...</td>\n",
              "      <td>Intel gained a total of $13,014 million in int...</td>\n",
              "      <td>Intel gained $13,014 million in intangibles su...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.945473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can you list all the Intel Goodwill activities...</td>\n",
              "      <td>[—\\n$\\n4,356\\nData Center Group\\n2,404\\n2,831\\...</td>\n",
              "      <td>- Data Center Group: $2,404 million\\n- Interne...</td>\n",
              "      <td>Sure, here are the Intel Goodwill activities f...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can let me know how much was spent on Data Cen...</td>\n",
              "      <td>[Disaggregated net revenue for each period was...</td>\n",
              "      <td>In 2016, the amount spent on the Data Center G...</td>\n",
              "      <td>In 2016, the amount spent on the Data Center G...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.946152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can you let me know the Identified intangible ...</td>\n",
              "      <td>[(3,634) $\\n12,745\\nDecember 31, 2016\\n(In Mil...</td>\n",
              "      <td>Identified intangible assets subject to amorti...</td>\n",
              "      <td>The Identified intangible assets subject to am...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.960631</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-491d9ef2-942d-4f7d-9f08-ba54f32266f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-491d9ef2-942d-4f7d-9f08-ba54f32266f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-491d9ef2-942d-4f7d-9f08-ba54f32266f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10e44c33-a061-49ed-8c65-090419fb3aab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10e44c33-a061-49ed-8c65-090419fb3aab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10e44c33-a061-49ed-8c65-090419fb3aab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bd4f1016-c616-48b0-8bb1-ffcec2a04245\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bd4f1016-c616-48b0-8bb1-ffcec2a04245 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"How much did Intangibles such as Goodwill and other identified intangible assets did Intel gain by acquiring Altera in millions?\",\n          \"Can you let me know the Identified intangible assets subject to amortization and show the difference between 2016 and 2017?\",\n          \"Can you list all the Intel Goodwill activities for year 2017 along with figures in millions?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Intel gained a total of $13,014 million in intangibles, including $5,448 million in Goodwill and $7,566 million in identified intangible assets, by acquiring Altera.\",\n          \"Identified intangible assets subject to amortization for 2016 were $8,686 million, and for 2017 were $10,577 million. The difference between 2016 and 2017 is $1,891 million.\",\n          \"- Data Center Group: $2,404 million\\n- Internet of Things Group: $428 million\\n- Intel Security Group: $3,599 million\\n- Software and Services Group: $441 million\\n- Programmable Solutions Group: $0 million\\n- All other: $382 million\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Intel gained $13,014 million in intangibles such as Goodwill and other identified intangible assets by acquiring Altera.\",\n          \"The Identified intangible assets subject to amortization for 2016 were $8,686 million, and for 2017, they were $10,577 million. The difference between 2016 and 2017 is $1,891 million.\",\n          \"Sure, here are the Intel Goodwill activities for the year 2017 along with figures in millions:- Client Computing Group: $4,356;- Data Center Group: $5,421;- Internet of Things Group: $1,126;- Programmable Solutions Group: $2,490;- All other: $10,996;Total: $24,389 million\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44721359548318745,\n        \"min\": 0.0,\n        \"max\": 0.999999999975,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.99999999995,\n          0.0,\n          0.999999999975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2173067468400883,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          0.3333333333333333,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23570226039551587,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5,\n          0.0,\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03754166426940269,\n        \"min\": 0.8759480815998613,\n        \"max\": 0.9722716303479442,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9454733826924263,\n          0.9606311021226306,\n          0.8759480815998613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=dataset,\n",
        "    metrics=[\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "    ],\n",
        ")\n",
        "\n",
        "df = result.to_pandas()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGN9VkH72AId",
        "outputId": "85a3c88d-a226-4c67-b0d6-8aadc30c9960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers torch accelerate bitsandbytes langchain --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-uqy03u2z0i"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-huggingface\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code snippet is responsible for loading a pre-trained language model called \"Mistral-Small-24B-Instruct-2501\" from Hugging Face using specific optimizations for memory efficiency.\n",
        "\n",
        "Please note here the Model was initially loaded from mistralai/Mistral-Small-24B-Instruct-2501 and saved locally for future use\n",
        "\n",
        "Here, the code is setting up configuration for model quantization using\n",
        "\n",
        "**BitsAndBytesConfig.**\n",
        "Quantization is a technique used to reduce the memory footprint and computational requirements of a model by representing its weights and activations with lower precision (fewer bits).\n",
        "\n",
        "**load_in_4bit=True** indicates that the model will be loaded using 4-bit quantization.\n",
        "\n",
        "**bnb_4bit_compute_dtype=torch.bfloat16** specifies that the computations within the quantized model will be performed using a data type called \"bfloat16\" which offers a balance between precision and memory usage."
      ],
      "metadata": {
        "id": "0GJW5HK8e_R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install decord"
      ],
      "metadata": {
        "id": "qHLM-JYOnale"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "AMQyQa_dYDom",
        "outputId": "f430cc9f-434f-42ba-bfe7-c9b3fb29fdc6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):\ncannot import name 'is_decord_available' from 'transformers.utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__path__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mextra_objects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mextra_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_rope_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mROPE_INIT_FUNCTIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALL_ATTENTION_FUNCTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdpa_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msdpa_attention_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOSS_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m from .pytorch_utils import (  # noqa: F401\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss_deformable_detr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeformableDetrForObjectDetectionLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeformableDetrForSegmentationLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss_for_object_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mForObjectDetectionLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForSegmentationLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/loss/loss_deformable_detr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_to_corners_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_scipy_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from .image_utils import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_decord_available' from 'transformers.utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a1239f216049>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load the model using the model ID and quantization configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m             )\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m             return model_class.from_pretrained(\n\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m     \u001b[0msupported_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msupported_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;31m# Maybe there was several model types associated with this config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_missing_backend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mextra_objects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mextra_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_import_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0;31m# This can be removed once every exportable object has a `export()` export.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):\ncannot import name 'is_decord_available' from 'transformers.utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py)"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from transformers import TextIteratorStreamer\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from threading import Thread\n",
        "import time\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "first_token_time = 0\n",
        "token_times = []\n",
        "\n",
        "# Define the model ID for the desired model.\n",
        "# Here the Model was initially loaded from mistralai/Mistral-Small-24B-Instruct-2501 and saved locally for future use.\n",
        "#model_id = f\"{data_dir}/LLMs/Mistral/Mistral-Small-24B-Instruct-2501\"\n",
        "model_path = f\"{data_dir}/LLMs/Mistral/\"\n",
        "\n",
        "\n",
        "\n",
        "# Define the quantization configuration for the model\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load the model using the model ID and quantization configuration\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    quantization_config=quantization_config,\n",
        "    trust_remote_code=True,\n",
        "    device_map='auto')\n",
        "\n",
        "# Load the tokenizer associated with the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_path,\n",
        "    trust_remote_code=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the model and tokenizer allows to load them from my Google Drive, saving time and bandwidth.**"
      ],
      "metadata": {
        "id": "aYPsgICpRq1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_pretrained(f\"{data_dir}/LLMs/Mistral\")\n",
        "#tokenizer.save_pretrained(f\"{data_dir}/LLMs/Mistral\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4NRsNJ5QX7w",
        "outputId": "d9fdd0ae-090e-4384-85ba-4a0f3c59e8b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/LLMs/Mistral/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/LLMs/Mistral/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/LLMs/Mistral/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "2K1kCxarwCcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47e02ca-6e67-4674-e3c1-5410e3418bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context before prompt: first=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7cb56b507f10>, search_kwargs={}) middle=[] last=RunnableLambda(format_docs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Identified intangible assets subject to amortization for December 31, 2016, and December 30, 2017, are shown below:\n",
            "\n",
            "    **December 31, 2016:**\n",
            "    - Gross Assets: $12,226 million\n",
            "    - Accumulated Amortization: $(3,540) million\n",
            "    - Net: $8,686 million\n",
            "\n",
            "    **December 30, 2017:**\n",
            "    - Gross Assets: $14,211 million\n",
            "    - Accumulated Amortization: $(3,634) million\n",
            "    - Net: $10,577 million\n",
            "\n",
            "    To find the difference between 2016 and 2017:\n",
            "\n",
            "    **Difference in Gross Assets:**\n",
            "    - 2017 Gross Assets: $14,211 million\n",
            "    - 2016 Gross Assets: $12,226 million\n",
            "    - Difference: $14,211 million - $12,226 million = $1,985 million\n",
            "\n",
            "    **Difference in Accumulated Amortization:**\n",
            "    - 2017 Accumulated Amortization: $(3,634) million\n",
            "    - 2016 Accumulated Amortization: $(3,540) million\n",
            "    - Difference: $(3,634) million - $(3,540) million = $(94) million\n",
            "\n",
            "    **Difference in Net:**\n",
            "    - 2017 Net: $10,577 million\n",
            "    - 2016 Net: $8,686 million\n",
            "    - Difference: $10,577 million - $8,686 million = $1,891 million\n",
            "\n",
            "    So, the differences between 2016 and 2017 for Identified intangible assets subject to amortization are:\n",
            "    - Gross Assets: $1,985 million increase\n",
            "    - Accumulated Amortization: $94 million increase (in absolute terms)\n",
            "    - Net: $1,891 million increase\n",
            "\n",
            "Printing Inference Metrics\n",
            "\n",
            "\n",
            "\n",
            "Time To First Token (TTFT): 1.652787208557129\n",
            "Inter-token latency (ITL): 0.8921384618680572\n",
            "End-to-end Latency: 32.7747368812561\n",
            "Throughput: 14.645426498435517\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'TTFT': 1.652787208557129,\n",
              " 'ITL': 0.8921384618680572,\n",
              " 'End-to-end Latency': 32.7747368812561,\n",
              " 'Throughput': 14.645426498435517}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "streaming_inference(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain provides a framework for building complex language model applications. By wrapping the Hugging Face model in a HuggingFacePipeline, it can be easily integrated with other LangChain components (like retrievers, prompts, and output parsers) to create a more sophisticated workflow.\n",
        "\n",
        "**streamer =:** This part is simply assigning the created object to a variable named streamer. This allows you to refer to and use the streamer object later in your code.\n",
        "\n",
        "**TextIteratorStreamer(...):** This is where the object is actually created. TextIteratorStreamer is a class from the transformers library designed to handle the streaming of text generation.\n",
        "\n",
        "**tokenizer:** This argument is passing the tokenizer object you created earlier (tokenizer = AutoTokenizer.from_pretrained(model_id)). The tokenizer is responsible for breaking down the text into tokens that the model can understand.\n",
        "\n",
        "**timeout=10.:** This sets a timeout of 10 seconds for the text queue. If the queue doesn't receive any new text within this time, it will raise a timeout exception. This helps to prevent the process from hanging indefinitely if there is a problem with the text generation.\n",
        "\n",
        "**skip_prompt=True:** This tells the streamer to skip the initial prompt text when outputting the generated text. This is useful to avoid repeating the prompt that was already provided to the model.\n",
        "\n",
        "**skip_special_tokens=True:** This instructs the streamer to skip any special tokens when outputting the generated text. Special tokens are often used by language models for internal purposes and are not meant to be part of the visible output."
      ],
      "metadata": {
        "id": "OiURkaSpg3oM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "fwBrI4FAYufV"
      },
      "outputs": [],
      "source": [
        "def streaming_inference(question):\n",
        "\n",
        "    context=retriever | format_docs\n",
        "    #{\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    print(f\"Context before prompt: {context}\")\n",
        "\n",
        "    # Initialize a TextIteratorStreamer object for streaming text generation\n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout=10.,\n",
        "                                    skip_prompt=True,\n",
        "                                    skip_special_tokens=True)\n",
        "\n",
        "    # Create a text generation pipeline using the Hugging Face transformers library\n",
        "    text_generation_pipeline = transformers.pipeline(\n",
        "        model=model,\n",
        "        #The tokenizer variable (also defined earlier) is responsible for converting text into a format that the model can understand.\n",
        "        tokenizer=tokenizer,\n",
        "        task=\"text-generation\",\n",
        "        #This parameter controls the randomness of the generated text. Lower values (closer to 0) make the output more deterministic and focused, while higher values (closer to 1) introduce more creativity and randomness.\n",
        "        temperature=0.3,\n",
        "        #This parameter discourages the model from repeating the same phrases or words by penalizing repetitions in the generated text. A value greater than 1 increases the penalty for repetitions.\n",
        "        repetition_penalty=1.1,\n",
        "        #This limits the maximum number of new tokens (words or sub-words) that the model can generate.\n",
        "        max_new_tokens=1000,\n",
        "        #This enables sampling during text generation, allowing the model to explore different possibilities and produce more diverse outputs.\n",
        "        do_sample= True,\n",
        "        #This argument incorporates a streamer object (likely an instance of TextIteratorStreamer), enabling the pipeline to generate text in a streaming fashion. This means the text is produced and outputted gradually, rather than waiting for the entire generation process to complete before displaying any results. This is helpful for providing immediate feedback and handling long text generation tasks more efficiently.\n",
        "        streamer=streamer  # Use the streamer for streaming text generation\n",
        "    )\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "    ### [INST]\n",
        "    Instruction: You are an AI language model Accounting assistant.Answer the following question based on this context.\n",
        "\n",
        "    ### CONTEXT:\n",
        "    {context}\n",
        "\n",
        "    ### QUESTION:\n",
        "    {question}\n",
        "\n",
        "    [/INST]\n",
        "    \"\"\"\n",
        "    # Line is taking a Hugging Face text generation model (set up earlier in the code) and wrapping it in a LangChain object\n",
        "    # so that it can be used as part of a larger language model application built with LangChain.\n",
        "    mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "    llm = mistral_llm\n",
        "    final_rag_chain = (\n",
        "        #{\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "\n",
        "        RunnablePassthrough.assign(\n",
        "            context=lambda x: format_docs(vectordb.similarity_search(x[\"question\"], k=10)),\n",
        "        )\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    input_text = {\n",
        "        \"context\": context,\n",
        "        \"question\": question\n",
        "    }\n",
        "\n",
        "    # Initialize variables for time measurements\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Start a new thread to invoke the language model chain with the input text\n",
        "    thread = Thread(target=final_rag_chain.invoke, args=[input_text])\n",
        "    thread.start()\n",
        "\n",
        "    # Initialize a variable to store the model output\n",
        "    model_output = \"\"\n",
        "\n",
        "    # Iterate over the streamer to get the generated text in chunks\n",
        "    for i, new_text in enumerate(streamer):\n",
        "        model_output += new_text\n",
        "        print(new_text, end='')\n",
        "\n",
        "        # Measure time for the first token\n",
        "        if i == 0:\n",
        "            first_token_time = time.time()\n",
        "        # Measure time for each token\n",
        "        token_times.append(time.time())\n",
        "\n",
        "    # Calculate end-to-end latency\n",
        "    end_time = time.time()\n",
        "    end_to_end_latency = end_time - start_time\n",
        "\n",
        "    # Calculate time to first token\n",
        "    ttft = first_token_time - start_time\n",
        "\n",
        "    # Calculate inter-token latency\n",
        "    itl = sum(x - y for x, y in zip(token_times[1:], token_times[:-1])) / (len(token_times) - 1)\n",
        "\n",
        "    # Calculate throughput\n",
        "    throughput = len(tokenizer.encode(model_output)) / end_to_end_latency\n",
        "\n",
        "    print(\"\\n\")  # Add a line break\n",
        "    print(\"Printing Inference Metrics\")\n",
        "    print(\"\\nTime To First Token (TTFT):\", ttft)\n",
        "    print(\"Inter-token latency (ITL):\", itl)\n",
        "    print(\"End-to-end Latency:\", end_to_end_latency)\n",
        "    print(\"Throughput:\", throughput)\n",
        "    print(\"\\n\")  # Add a line break\n",
        "    # Return the metrics\n",
        "    return {\n",
        "        \"TTFT\": ttft,\n",
        "        \"ITL\": itl,\n",
        "        \"End-to-end Latency\": end_to_end_latency,\n",
        "        \"Throughput\": throughput\n",
        "    }"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMuc73S/tR0E0zsusVAn0GN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f5ec9b7886b40bfa5c08f2c6fc27f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19ab3a5cfbef4541889a5703b25d848a",
              "IPY_MODEL_84ceda66e52046788c1697e4bff932ec",
              "IPY_MODEL_3c458ce5565b4f5ca1271beb9c9dcfa0"
            ],
            "layout": "IPY_MODEL_328088bf6bf5414c870455e9ce7d9dcb"
          }
        },
        "19ab3a5cfbef4541889a5703b25d848a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a5ceffb89b49fdaaf298b92abc667e",
            "placeholder": "​",
            "style": "IPY_MODEL_f1820773b6794df9917e7f8230eb509d",
            "value": "Evaluating: 100%"
          }
        },
        "84ceda66e52046788c1697e4bff932ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e625f0268d4874a86f4fee384dc4e3",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84b5727cc569492da6b78ab163a2dc6a",
            "value": 20
          }
        },
        "3c458ce5565b4f5ca1271beb9c9dcfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dccdfedb7bc47d3b86e1c9b455f8bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_ee2d071a66cb41f8978d1a203d3d93ff",
            "value": " 20/20 [00:12&lt;00:00,  2.85it/s]"
          }
        },
        "328088bf6bf5414c870455e9ce7d9dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a5ceffb89b49fdaaf298b92abc667e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1820773b6794df9917e7f8230eb509d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5e625f0268d4874a86f4fee384dc4e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b5727cc569492da6b78ab163a2dc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dccdfedb7bc47d3b86e1c9b455f8bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2d071a66cb41f8978d1a203d3d93ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}